{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab2 TP2043 Text Preprocessing_Normalization.ipynb","provenance":[{"file_id":"1nqzFzL83NZYQ4g0R_IJOW4cGav-Eoxvd","timestamp":1650957513028}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Lab 2 : Text Preprocessing (Normalization)\n","\n","Student Name  : Chong Wei Yi\n","\n","Student Number: A180497"],"metadata":{"id":"iRkoujykMOic"}},{"cell_type":"markdown","source":["In this activity, we will observe methods for text normalization as follows:\n","\n","1) Stemming\n","\n","2) Lemmatization"],"metadata":{"id":"QyqRf88WMU4B"}},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","\n","\n","# Get stopwords, stemmer and lemmatizer\n","stopwords = nltk.corpus.stopwords.words('english')\n","stemmer = nltk.stem.PorterStemmer()\n","lemmatizer = nltk.stem.WordNetLemmatizer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lF-m-_letb8V","executionInfo":{"status":"ok","timestamp":1650960573563,"user_tz":-480,"elapsed":327,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"055079c5-4431-42e8-d8bf-0d33cb19337f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["input_sentence = \"The government has gradually relaxed the Covid-19 SOP following the transition towards endemicity beginning April 1. The Ministry of Health don’t want to make a mistake in whatever relaxation of the SOP to ensure it is safely and carefully done.\"\n","# Split to tokens\n","tokens = nltk.word_tokenize(input_sentence)\n","print(tokens)"],"metadata":{"id":"E3u2pMLbvi6Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960573878,"user_tz":-480,"elapsed":12,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"b2351ac3-9727-4a31-fb17-418d5a6b6212"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'government', 'has', 'gradually', 'relaxed', 'the', 'Covid-19', 'SOP', 'following', 'the', 'transition', 'towards', 'endemicity', 'beginning', 'April', '1', '.', 'The', 'Ministry', 'of', 'Health', 'don', '’', 't', 'want', 'to', 'make', 'a', 'mistake', 'in', 'whatever', 'relaxation', 'of', 'the', 'SOP', 'to', 'ensure', 'it', 'is', 'safely', 'and', 'carefully', 'done', '.']\n"]}]},{"cell_type":"markdown","source":["### Stemming"],"metadata":{"id":"8D4nFIRlrsvP"}},{"cell_type":"code","source":["#ps = PorterStemmer()\n","result_stemming = [stemmer.stem(i) for i in tokens] # for each token in the sentence it will find the stemmer\n","print(result_stemming)\n"],"metadata":{"id":"T2LNQsglr96n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960573878,"user_tz":-480,"elapsed":10,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"509846e7-d7b8-4976-d7b1-ffe9ac97db43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'govern', 'ha', 'gradual', 'relax', 'the', 'covid-19', 'sop', 'follow', 'the', 'transit', 'toward', 'endem', 'begin', 'april', '1', '.', 'the', 'ministri', 'of', 'health', 'don', '’', 't', 'want', 'to', 'make', 'a', 'mistak', 'in', 'whatev', 'relax', 'of', 'the', 'sop', 'to', 'ensur', 'it', 'is', 'safe', 'and', 'care', 'done', '.']\n"]}]},{"cell_type":"markdown","source":["### Lemmatization"],"metadata":{"id":"z_oynlA6vvoH"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","wnl = WordNetLemmatizer()\n","nltk.download('wordnet') # english dictionary"],"metadata":{"id":"RnqUcmDrv0Dt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960573879,"user_tz":-480,"elapsed":9,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"d918966b-5fa2-4b13-8e4a-6e5d378a1bf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["result_lemmatization_noun = [wnl.lemmatize(i, 'n') for i in tokens]\n","print(result_lemmatization_noun)"],"metadata":{"id":"OZo4fRaiv_as","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960574278,"user_tz":-480,"elapsed":406,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"402fb91a-ebcc-413d-92a2-ca90a3548c91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'government', 'ha', 'gradually', 'relaxed', 'the', 'Covid-19', 'SOP', 'following', 'the', 'transition', 'towards', 'endemicity', 'beginning', 'April', '1', '.', 'The', 'Ministry', 'of', 'Health', 'don', '’', 't', 'want', 'to', 'make', 'a', 'mistake', 'in', 'whatever', 'relaxation', 'of', 'the', 'SOP', 'to', 'ensure', 'it', 'is', 'safely', 'and', 'carefully', 'done', '.']\n"]}]},{"cell_type":"code","source":["result_lemmatization_verb = [wnl.lemmatize(i, 'v') for i in tokens]\n","print(result_lemmatization_verb)\n"],"metadata":{"id":"BtmIJ-MnwF-k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960574279,"user_tz":-480,"elapsed":8,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"aa691407-31b5-4c72-82f9-a46f00a2b54f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'government', 'have', 'gradually', 'relax', 'the', 'Covid-19', 'SOP', 'follow', 'the', 'transition', 'towards', 'endemicity', 'begin', 'April', '1', '.', 'The', 'Ministry', 'of', 'Health', 'don', '’', 't', 'want', 'to', 'make', 'a', 'mistake', 'in', 'whatever', 'relaxation', 'of', 'the', 'SOP', 'to', 'ensure', 'it', 'be', 'safely', 'and', 'carefully', 'do', '.']\n"]}]},{"cell_type":"markdown","source":["###**Observe and compare the stemming and lemmatization results. Describe the advantage and disadvantage for stemming and lemmatization.**\n","\n","Answer: (write your answer here)\n","\n","### **Stemming**\n","**Result:** Cuts off/ stem the end of the wordtaking into account a list of common prefixes and suffixes that can be found in an inflected word\n","**Example:** \n","1. government --> govern, \n","2. mistake--> mistak, \n","3. whatever-->whatev\n","**Advantage:**\n","1. typically easier to implement and run faster, and the reduced accuracy may not matter for some applications.\n","2. reduces word-forms to (pseudo)stems\n","3. freely available implementations and that there is no need of lexicons, which have to be maintained.\n","**Disadvantage:**\n","1. leads to incorrect meanings and spelling after removing the last few characters of a word\n","as a stemmer operates on a single word without knowledge of the context\n","2. the quality of stemming often is bad.\n","\n","### **Lemmatization**\n","**Result:** Replace character of the end of the word and considers the morphological analysis of words.\n","\n","**Example:**\n","1. has --> have\n","2. relaxed --> relax\n","3. beginning --> begin\n","**Advantage:**\n","1. considers the context and converts the word to its meaningful base form, which is called Lemma.\n","2. will return the dictionary form of a word, which must be a valid word\n","3. reduces the word-forms to linguistically valid lemmas\n","**Disadvantage**\n","1. lemmatization involves deriving the meaning of a word from something like a dictionary, it's very time consuming. \n","2. most lemmatization algorithms are slower compared to their stemming counterparts.\n"],"metadata":{"id":"Q87SvWIKxAtH"}}]}